diff --git a/aten/src/THCUNN/IndexLinear.cu b/aten/src/THCUNN/IndexLinear.cu
index 2729f9277..98ac09ece 100644
--- a/aten/src/THCUNN/IndexLinear.cu
+++ b/aten/src/THCUNN/IndexLinear.cu
@@ -22,7 +22,11 @@ __device__ double atomicExch(double *address, double val) {
 }
 
 template<typename Ty, bool train>
+#if defined(__HIP_PLATFORM_HCC__)
+__global__ 
+#else
 __global__ static
+#endif
 void updateOutput(
     Ty *output,
     Ty *normalizedValues,
@@ -141,7 +145,11 @@ void updateOutput(
 // to generate gradWeight of size [keysSize x outDim]
 // nth block along y dimension computes on the non zero elements from the nth batch.
 template<typename Ty>
+#if defined(__HIP_PLATFORM_HCC__)
+__global__ 
+#else
 __global__ static
+#endif
 void accGradWeight(
     Ty *gradWeight,
     const Ty *gradOutput,
@@ -213,7 +221,11 @@ void accGradWeight(
 // The gradBias is just a reduction of gradOutput along the batches.
 // There is only one block along y dimension performing the reduction.
 template<typename Ty, bool update>
+#if defined(__HIP_PLATFORM_HCC__)
+__global__ 
+#else
 __global__ static
+#endif
 void accGradBias(
     Ty *buffer,
     const Ty *gradOutput,
@@ -267,7 +279,11 @@ void accGradBias(
 // This kernel is launched batchSize number of times.
 // At each step in the iteration, the weights are updated in a sparse manner.
 template<typename Ty>
+#if defined(__HIP_PLATFORM_HCC__)
+__global__ 
+#else
 __global__ static
+#endif
 void updateWeight(
     Ty *weight,
     const Ty *gradWeight,
@@ -336,7 +352,11 @@ void updateWeight(
 // This kernel is launched batchSize number of times.
 // At each step in the iteration, the weights are updated in place in a sparse manner.
 template<typename Ty>
+#if defined(__HIP_PLATFORM_HCC__)
+__global__ 
+#else
 __global__ static
+#endif
 void accUpdateWeight(
     Ty *weight,
     const int64_t weightStride,
