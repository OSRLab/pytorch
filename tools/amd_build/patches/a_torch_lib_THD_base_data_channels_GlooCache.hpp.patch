diff --git a/torch/lib/THD/base/data_channels/GlooCache.hpp b/torch/lib/THD/base/data_channels/GlooCache.hpp
index eaed54aff..0f0577e68 100644
--- a/torch/lib/THD/base/data_channels/GlooCache.hpp
+++ b/torch/lib/THD/base/data_channels/GlooCache.hpp
@@ -9,7 +9,7 @@
 #include "gloo/allreduce_ring.h"
 #include "gloo/barrier_all_to_all.h"
 #include "gloo/broadcast_one_to_all.h"
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
 #include "gloo/cuda_allreduce_ring.h"
 #include "gloo/cuda_allreduce_halving_doubling.h"
 #include "gloo/cuda_allreduce_halving_doubling_pipelined.h"
@@ -19,7 +19,7 @@
 #include "gloo/rendezvous/store.h"
 #include "gloo/rendezvous/prefix_store.h"
 
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
 #include <cuda.h>
 #include <THC/THC.h>
 #endif
@@ -141,7 +141,7 @@ struct GlooCache {
     if (device == DeviceType::CPU) {
       return std::shared_ptr<buffer_type>(new char[bytes],
                                           std::default_delete<char[]>());
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
     } else if (device == DeviceType::CUDA) {
       buffer_type *buf;
       THCudaCheck(THCudaMalloc(THDGetCudaState(), (void**)&buf, bytes));
@@ -184,7 +184,7 @@ struct GlooCache {
 
     if (t_dev == DeviceType::CPU) {
       std::memcpy(input_buffer, t.data_ptr(), tensor_bytes);
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
     } else if (t_dev == DeviceType::CUDA) {
       auto stream = THCState_getCurrentStream(THDGetCudaState());
       THCudaCheck(cudaMemcpyAsync(input_buffer, t.data_ptr(), tensor_bytes,
@@ -202,7 +202,7 @@ struct GlooCache {
 
     if (t_dev == DeviceType::CPU) {
       std::memcpy(t.data_ptr(), output_buffer, tensor_bytes);
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
     } else if (t_dev == DeviceType::CUDA) {
       auto stream = THCState_getCurrentStream(THDGetCudaState());
       THCudaCheck(cudaMemcpyAsync(t.data_ptr(), output_buffer, tensor_bytes,
@@ -318,7 +318,7 @@ struct algorithm_spec<CollectiveType::ALL_REDUCE, T> {
         std::initializer_list<T*>{reinterpret_cast<T*>(input_buffer.get())},
         count,
         THDToGlooReduceOp<T>(op));
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
     } else if (device == DeviceType::CUDA) {
       if (op != THDReduceSUM) {
         throw std::runtime_error("Gloo backend only supports sum op for CUDA all reduce");
@@ -388,7 +388,7 @@ struct algorithm_spec<CollectiveType::BROADCAST, T> {
         std::initializer_list<T*>{reinterpret_cast<T*>(input_buffer.get())},
         count,
         src_rank);
-#ifdef WITH_CUDA
+#ifdef WITH_ROCM
     } else if (device == DeviceType::CUDA) {
       auto stream = THCState_getCurrentStream(THDGetCudaState());
 
